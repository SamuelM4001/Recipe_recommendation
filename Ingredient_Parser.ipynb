{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing the ingredients.\n",
    "\n",
    "1. First converting the string data into a list\n",
    "2. Removing stop words, measures, junk words, etc and only keeping actual ingredients in the column using some NLP techniques \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On inspection of the data_cleaned file (in MS word), I've made a list of measures and junk words that I'll need to remove which I'll use now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import unidecode\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the ingredient parser function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ingredient_parser(ingreds):\n",
    "    measures = ['teaspoon', 't', 'tsp.', 'tablespoon', 'T', 'tbl.', 'tb', 'tbsp.', 'fluid ounce', 'fl oz', 'gill', 'cup', 'c', 'pint', 'p', 'pt', 'fl pt',\n",
    "                'quart', 'q', 'qt', 'fl qt', 'gallon', 'g', 'gal', 'ml', 'milliliter', 'millilitre', 'cc', 'mL', 'l', 'liter', 'litre', 'L', 'dl', 'deciliter',\n",
    "                'decilitre', 'dL', 'bulb', 'level', 'heaped', 'rounded', 'whole', 'pinch', 'medium', 'slice', 'pound', 'lb', '#', 'ounce', 'oz', 'mg', 'milligram',\n",
    "                'milligramme', 'g', 'gram', 'gramme', 'kg', 'kilogram', 'kilogramme', 'x', 'of', 'mm', 'millimetre', 'millimeter', 'cm', 'centimeter', 'centimetre',\n",
    "                'm', 'meter', 'metre', 'inch', 'in', 'milli', 'centi', 'deci', 'hecto', 'kilo']\n",
    "    \n",
    "    words_to_remove = ['fresh', 'oil', 'a', 'red', 'bunch', 'and', 'clove', 'or', 'leaf', 'chilli', 'large', 'extra', 'sprig', 'ground', 'handful', 'free',\n",
    "                       'small', 'pepper', 'virgin', 'range', 'from', 'dried', 'sustainable', 'black', 'peeled', 'higher', 'welfare', 'seed', 'for', 'finely',\n",
    "                       'freshly', 'sea', 'quality', 'white', 'ripe', 'few', 'piece', 'source', 'to', 'organic', 'flat', 'smoked', 'ginger', 'sliced', 'green',\n",
    "                       'picked', 'the', 'stick', 'plain', 'plus', 'mixed', 'mint', 'bay', 'basil', 'your', 'cumin', 'optional', 'fennel', 'serve', 'mustard', \n",
    "                       'unsalted', 'baby', 'paprika', 'fat', 'ask', 'natural', 'skin', 'roughly', 'into', 'such', 'cut', 'good', 'brown', 'grated', 'trimmed',\n",
    "                       'oregano', 'powder', 'yellow', 'dusting', 'knob', 'frozen', 'on', 'deseeded', 'low', 'runny', 'balsamic', 'cooked', 'streaky', 'nutmeg', \n",
    "                       'sage', 'rasher', 'zest', 'pin', 'groundnut', 'breadcrumb', 'turmeric', 'halved', 'grating', 'stalk', 'light', 'tinned', 'dry', 'soft', \n",
    "                       'rocket', 'bone', 'colour', 'washed', 'skinless', 'leftover', 'splash', 'removed', 'dijon', 'thick', 'big', 'hot', 'drained', 'sized', \n",
    "                       'chestnut', 'watercress', 'fishmonger', 'english', 'dill', 'caper', 'raw', 'worcestershire', 'flake', 'cider', 'cayenne', 'tbsp', 'leg',\n",
    "                       'pine', 'wild', 'if', 'fine', 'herb', 'almond', 'shoulder', 'cube', 'dressing', 'with', 'chunk', 'spice', 'thumb', 'garam', 'new', 'little',\n",
    "                       'punnet', 'peppercorn', 'shelled', 'saffron', 'other''chopped', 'salt', 'olive', 'taste', 'can', 'sauce', 'water', 'diced', 'package', 'italian',\n",
    "                       'shredded', 'divided', 'parsley', 'vinegar', 'all', 'purpose', 'crushed', 'juice', 'more', 'coriander', 'bell', 'needed', 'thinly', 'boneless',\n",
    "                       'half', 'thyme', 'cubed', 'cinnamon', 'cilantro', 'jar', 'seasoning', 'rosemary', 'extract', 'sweet', 'baking', 'beaten', 'heavy', 'seeded', 'tin',\n",
    "                       'vanilla', 'uncooked', 'crumb', 'style', 'thin', 'nut', 'coarsely', 'spring', 'chili', 'cornstarch', 'strip', 'cardamom', 'rinsed', 'honey', 'cherry',\n",
    "                       'root', 'quartered', 'head', 'softened', 'container', 'crumbled', 'frying', 'lean', 'cooking', 'roasted', 'warm', 'whipping', 'thawed', 'corn', \n",
    "                       'pitted','sun', 'kosher', 'bite', 'toasted', 'lasagna', 'split', 'melted', 'degree', 'lengthwise', 'romano', 'packed', 'pod', 'anchovy', 'rom',\n",
    "                       'prepared', 'juiced','fluid', 'floret', 'room', 'active', 'seasoned', 'mix', 'deveined', 'lightly', 'anise', 'thai', 'size', 'unsweetened',\n",
    "                       'torn', 'wedge', 'sour', 'basmati','marinara', 'dark', 'temperature', 'garnish', 'bouillon', 'loaf', 'shell', 'reggiano', 'canola', 'parmigiano',\n",
    "                        'round', 'canned', 'ghee', 'crust', 'long', 'broken', 'ketchup', 'bulk', 'cleaned', 'condensed', 'sherry', 'provolone', 'cold', 'soda',\n",
    "                        'cottage', 'spray', 'tamarind', 'pecorino', 'shortening', 'part', 'bottle', 'sodium', 'cocoa', 'grain', 'french', 'roast', 'stem', 'link',\n",
    "                        'firm', 'asafoetida', 'mild', 'dash', 'boiling','ADVERTISEMENT', 'advertisement', 'chopped', 'only', 'minced','weed']\n",
    "    \n",
    "    #checking if input is a list, if not then converting string input to list\n",
    "    if isinstance(ingreds, list):\n",
    "        ingredients = ingreds\n",
    "    else:\n",
    "        ingredients = ingreds.split()\n",
    "        \n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    lemmatizer = WordNetLemmatizer() #lemmatization to get base word\n",
    "    ingred_list = []\n",
    "    \n",
    "    for i in ingredients:\n",
    "        i = i.translate(translator)\n",
    "        # We split up with hyphens as well as spaces\n",
    "        items = re.split(' |-', i)\n",
    "        # Get rid of words containing non alphabet letters\n",
    "        items = [word for word in items if word.isalpha()]\n",
    "        # Turn everything to lowercase\n",
    "        items = [word.lower() for word in items]\n",
    "        # remove accents\n",
    "        items = [unidecode.unidecode(word) for word in items] #''.join((c for c in unicodedata.normalize('NFD', items) if unicodedata.category(c) != 'Mn'))\n",
    "        # Lemmatize words so we can compare words to measuring words\n",
    "        items = [lemmatizer.lemmatize(word) for word in items]\n",
    "        # Gets rid of measuring words/phrases, e.g. heaped teaspoon\n",
    "        items = [word for word in items if word not in measures]\n",
    "        # Get rid of common easy words\n",
    "        items = [word for word in items if word not in words_to_remove]\n",
    "        if items:\n",
    "            ingred_list.append(' '.join(items)) \n",
    "    ingred_list = \" \".join(ingred_list)\n",
    "    return ingred_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parsing the cleaned_data csv file and storing the result in new file 'parsed_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    recipe_df = pd.read_csv('C:/Users/ACER/Desktop/Recipe_Recommendation/jupyter notebooks/cleaned_data.csv')\n",
    "    recipe_df['Ingredients'] = recipe_df['Ingredients'].astype(str)\n",
    "    recipe_df['Parsed_Ingredients'] = recipe_df['Ingredients'].apply(lambda x: ingredient_parser(x))\n",
    "    df = recipe_df.dropna()\n",
    "    specified_columns = ['Title','Parsed_Ingredients','Instructions']\n",
    "    df = df[specified_columns]\n",
    "    df.to_csv('C:/Users/ACER/Desktop/Recipe_Recommendation/jupyter notebooks/parsed_data.csv')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Title', 'Parsed_Ingredients', 'Instructions'], dtype='object')\n",
      "                               Title  \\\n",
      "0  Slow Cooker Chicken and Dumplings   \n",
      "\n",
      "                                  Parsed_Ingredients  \\\n",
      "0  chicken breast butter cream chicken soup onion...   \n",
      "\n",
      "                                        Instructions  \n",
      "0  Place the chicken, butter, soup, and onion in ...  \n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df.head(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the data using TF-IDF  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Parsed_Ingredients'] = df.Parsed_Ingredients.values.astype('U') #ensuring the data is treated as unicode strings\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(df['Parsed_Ingredients']) #Basically makes the vectorizer go through the column and make a list of unique words\n",
    "tfidf_recipes = tfidf.transform(df['Parsed_Ingredients']) #transforms the data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving the model so we dont have to execute it again and again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/ACER/Desktop/Recipe_Recommendation/jupyter notebooks/trained_model.pickle', \"wb\") as f:\n",
    "    pickle.dump(tfidf, f)\n",
    "\n",
    "with open('C:/Users/ACER/Desktop/Recipe_Recommendation/jupyter notebooks/encoding.pickle', \"wb\") as f:\n",
    "    pickle.dump(tfidf_recipes, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
